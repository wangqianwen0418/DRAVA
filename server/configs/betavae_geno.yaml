model_params:
  name: 'BetaVAE_BIG_CONV'
  in_channels: 1
  latent_dim: 12 # for dsprites
  # latent_dim: 28 # for celeba
  img_size: 64
  hidden_dims: [16, 64, 256]
  # conv_sizes: [7,5,3] # default is [3,3,3] 
  loss_type: 'B'
  gamma: 10.0
  max_capacity: 25
  Capacity_max_iter: 10000

exp_params:
  # dataset: celeba
  dataset: HFFc6_ATAC_chr1-8
  data_path: "./data/"
  img_size: 64
  optimizer: "adam"
  batch_size: 256 # Better to have a square number
  LR: 0.0005
  weight_decay: 0.0
  scheduler_gamma: 0.95

trainer_params:
  gpus: 1
  max_nb_epochs: 200
  max_epochs: 200

logging_params:
  save_dir: "logs"
  name: "BetaVAE_TAD"
  manual_seed: 1265
